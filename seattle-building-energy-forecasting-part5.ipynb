{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Seattle Building Energy Forecasting\n",
    "\n",
    "URL: https://www.kaggle.com/city-of-seattle/sea-building-energy-benchmarking\n",
    "\n",
    "## Notebook nÂ°5 - Modelling\n",
    "\n",
    "Objective: Create dummy variables and try different models\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import librairies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import warnings\n",
    "import re\n",
    "import pickle\n",
    "import itertools\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import r2_score, mean_squared_error\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
    "from sklearn.model_selection import GridSearchCV, train_test_split, KFold\n",
    "import xgboost as xgb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set(style=\"whitegrid\")\n",
    "warnings.filterwarnings('ignore')\n",
    "pd.options.display.max_rows = 200\n",
    "\n",
    "target1 = \"SiteEnergyUse(kBtu)\"\n",
    "target2 = \"TotalGHGEmissions\"\n",
    "\n",
    "TARGET = target2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"data/part4.pkl\", \"rb\") as f:\n",
    "    my_unpickler = pickle.Unpickler(f)\n",
    "    data = my_unpickler.load()\n",
    "    \n",
    "with open(\"data/part4-data-with-outliers.pkl\", \"rb\") as f:\n",
    "    my_unpickler = pickle.Unpickler(f)\n",
    "    data_with_outliers = my_unpickler.load()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Functions\n",
    "\n",
    "### Dummify variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [],
   "source": [
    "def onehot(data, feature):\n",
    "    \n",
    "    # Get dummy variables\n",
    "    temp_df = pd.get_dummies(data[feature])\n",
    "    \n",
    "    # Add prefix to prevent duplicated feature names\n",
    "    temp_df = temp_df.add_prefix(feature + \"_\")\n",
    "    \n",
    "    # Concatenante the new features with the main dataframes\n",
    "    data = pd.concat([data, temp_df], axis=1)\n",
    "    \n",
    "    # Drop the original feature\n",
    "    data.drop(feature, axis=1, inplace=True)\n",
    "    \n",
    "    # Return the new dataframe\n",
    "    return data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_data(data, energystarscore=\"fill\"):\n",
    "    \n",
    "    # Copy original data\n",
    "    data_copy = data.copy()\n",
    "    \n",
    "    # Building Type\n",
    "    data_copy = onehot(data_copy, \"BuildingType\")\n",
    "    \n",
    "    # CouncilDistrictCode\n",
    "    data_copy = onehot(data_copy, \"CouncilDistrictCode\")\n",
    "    \n",
    "    # Neighborhood\n",
    "    data_copy = onehot(data_copy, \"Neighborhood\")\n",
    "    \n",
    "    # LargestPropertyUseType\n",
    "    data_copy = onehot(data_copy, \"LargestPropertyUseType\")\n",
    "    \n",
    "    # PrimaryPropertyType\n",
    "    data_copy = onehot(data_copy, \"PrimaryPropertyType\")\n",
    "    \n",
    "    # DataYear\n",
    "    data_copy.drop(\"DataYear\", axis=1, inplace=True)\n",
    "    \n",
    "    # Address\n",
    "    data_copy.drop(\"Address\", axis=1, inplace=True)\n",
    "    \n",
    "    # address_type\n",
    "    data_copy.drop(\"address_type\", axis=1, inplace=True)\n",
    "    \n",
    "    # lat_long_range\n",
    "    data_copy.drop(\"lat_long_range\", axis=1, inplace=True)\n",
    "    \n",
    "    # ZipCode\n",
    "    data_copy.drop(\"ZipCode\", axis=1, inplace=True)\n",
    "    \n",
    "    # default_data\n",
    "    data_copy.drop(\"default_data\", axis=1, inplace=True)\n",
    "    \n",
    "    # ENERGYSTARScore\n",
    "    if (energystarscore == \"fill\"):\n",
    "        data_copy[\"ENERGYSTARScore\"].fillna(data_copy[\"ENERGYSTARScore\"].dropna().mean(), inplace=True)\n",
    "    elif (energystarscore == \"drop\"):\n",
    "        mask = data_copy[\"ENERGYSTARScore\"].isna()\n",
    "        data_copy = data_copy[~mask]\n",
    "\n",
    "    return data_copy.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 298,
   "metadata": {},
   "outputs": [],
   "source": [
    "def my_rf(data, target, param_grid, test_size, target_log=False):\n",
    "\n",
    "    X = data.drop(target, axis=1)\n",
    "    y = data[target]\n",
    "    \n",
    "    if target_log:\n",
    "        y = np.log(data[target])\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=test_size, random_state=42)\n",
    "\n",
    "    scaler = StandardScaler()\n",
    "    scaler.fit(X_train)\n",
    "    X_train_scaled = scaler.transform(X_train)\n",
    "    X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "    score = 'neg_mean_squared_error'\n",
    "\n",
    "    # Cross validation classifier to get best parameters from the grid search\n",
    "    clf_rf = GridSearchCV(RandomForestRegressor(), param_grid, cv=5, scoring=score)\n",
    "    clf_rf.fit(X_train_scaled, y_train)\n",
    "    params = clf_rf.best_params_\n",
    "        \n",
    "    # Train prediction\n",
    "    y_train_pred = clf_rf.predict(X_train_scaled)\n",
    "    \n",
    "    # Test prediction\n",
    "    y_test_pred = clf_rf.predict(X_test_scaled)\n",
    "    \n",
    "    ############## Scores ##############\n",
    "    \n",
    "    # Get back to exponantial if we are in log for the target\n",
    "    if target_log:\n",
    "        y_train_pred = np.exp(y_train_pred)\n",
    "        y_train = np.exp(y_train)\n",
    "        y_test_pred = np.exp(y_test_pred)\n",
    "        y_test = np.exp(y_test)\n",
    "    \n",
    "    # Compute R2 and RMSE for both training set and test set\n",
    "    train_rmse = np.sqrt(mean_squared_error(y_train, y_train_pred))\n",
    "    train_r2 = r2_score(y_train, y_train_pred)\n",
    "    test_rmse = np.sqrt(mean_squared_error(y_test, y_test_pred))\n",
    "    test_r2 = r2_score(y_test, y_test_pred)\n",
    "    \n",
    "    # Push the score in a dict\n",
    "    scores = {\n",
    "        'train_rmse': train_rmse,\n",
    "        'train_r2': train_r2,\n",
    "        'test_rmse': test_rmse,\n",
    "        'test_r2': test_r2\n",
    "    }\n",
    "    \n",
    "    # Return the classifier, y test and scores\n",
    "    return clf_rf, y_test, y_test_pred, scores, X_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### XGboost Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 302,
   "metadata": {},
   "outputs": [],
   "source": [
    "def my_xgb(data, params, target, test_size=0.2):\n",
    "    \"\"\"This function performs a cross-validation test on the given data. For now, it's designed to run with the XGBoost algorithm.\n",
    "    \n",
    "    First, it splits the features and the target.\n",
    "    Then, it performs a train / test split if test_size != 0.\n",
    "    Then, it performs a K-Folds cross-validation with sklearn.\n",
    "    Finally, for each parameters combination it gives :\n",
    "    - The cross-validation score\n",
    "    - The training score\n",
    "    - The test score (if test_size != 0)\n",
    "    \n",
    "    The scores are R2 and RMSE, so the function is designed only for regression so far.\n",
    "    \n",
    "    Args:\n",
    "    \n",
    "        data (Pandas Dataframe): the original dataset\n",
    "        params (dict): the grid-search parameters. Each value has to be a list\n",
    "        target (str): The name of the target as written in the dataset column\n",
    "        test_size (float): The proportion of the test set ([0, 1[)\n",
    "        \n",
    "    Returns:\n",
    "        Dict: All the results for each parameters combination plus the corresponding model trained on the entire training set.\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    #########################################################################\n",
    "    # Prepare data : X / y split, then Train / test split, then scale\n",
    "    #########################################################################\n",
    "    \n",
    "    X = data.drop(target, axis=1)\n",
    "    y = data[target]\n",
    "    \n",
    "    if test_size != 0:\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=test_size, random_state=42)\n",
    "        \n",
    "    else:\n",
    "        X_train = X\n",
    "        y_train = y\n",
    "\n",
    "    scaler = StandardScaler()\n",
    "    scaler.fit(X_train)\n",
    "    X_train_scaled = scaler.transform(X_train)\n",
    "    X_test_scaled = scaler.transform(X_test)\n",
    "    \n",
    "    #########################################################################\n",
    "    # Prepare params for gridsearch. Compute all combinations\n",
    "    #########################################################################\n",
    "    \n",
    "    params_keys = list(params.keys())\n",
    "    params_product = list(itertools.product(*list(params.values())))\n",
    "    params_flatten = {params_keys[i]: [item[i] for item in params_product] for i in range(len(params_keys))}\n",
    "    \n",
    "    #########################################################################\n",
    "    # Prepare folds for cross-validation\n",
    "    #########################################################################\n",
    "    \n",
    "    kf = KFold(n_splits=5, random_state=42, shuffle=True)\n",
    "    \n",
    "    #########################################################################\n",
    "    # Prepare the results\n",
    "    #########################################################################\n",
    "    \n",
    "    results = {\n",
    "        'params': [],\n",
    "        'cv_r2_score': [],\n",
    "        'cv_rmse_score': [],\n",
    "        'train_r2_score': [],\n",
    "        'train_rmse_score': [],\n",
    "    }\n",
    "    \n",
    "    if test_size != 0:\n",
    "        results['test_r2_score'] = []\n",
    "        results['test_rmse_score'] = []\n",
    "        \n",
    "    results['model'] = []\n",
    "    \n",
    "    #########################################################################\n",
    "    # Parse all params combinations:\n",
    "    #########################################################################\n",
    "    \n",
    "    for i in range(len(params_flatten[list(params_flatten.keys())[0]])):\n",
    "        \n",
    "        # Construct the object \"temp_params\"\n",
    "        temp_params = {key: params_flatten[key][i] for key in params_flatten.keys()}\n",
    "        \n",
    "        # Cross Validation - Iterate over folds\n",
    "        temp_scores = {\n",
    "            'r2':[],\n",
    "            'rmse':[]\n",
    "        }\n",
    "        for train_index, test_index in kf.split(X_train_scaled):\n",
    "\n",
    "            # Train / Test split\n",
    "            \n",
    "            # X is a numpy array, so we just need to use indexes returned by the split\n",
    "            X_train_cv, X_test_cv = X_train_scaled[train_index], X_train_scaled[test_index]\n",
    "            \n",
    "            # y is an indexed Pandas series, so we need to use .iloc\n",
    "            y_train_cv, y_test_cv = y_train.iloc[train_index], y_train.iloc[test_index]\n",
    "\n",
    "            # Train the model\n",
    "            dtrain = xgb.DMatrix(X_train_cv, y_train_cv)\n",
    "            dtest = xgb.DMatrix(X_test_cv)\n",
    "            bst = xgb.train(temp_params, dtrain)\n",
    "            y_test_cv_pred = bst.predict(dtest)\n",
    "\n",
    "            # Save the score\n",
    "            temp_scores['r2'].append(r2_score(y_test_cv, y_test_cv_pred))\n",
    "            temp_scores['rmse'].append(np.sqrt(mean_squared_error(y_test_cv, y_test_cv_pred)))\n",
    "        \n",
    "        # Train the model on the entire train set\n",
    "        dtrain = xgb.DMatrix(X_train_scaled, y_train)\n",
    "        bst = xgb.train(temp_params, dtrain)\n",
    "        \n",
    "        # \"Prediction\" on train set\n",
    "        y_train_pred = bst.predict(dtrain)\n",
    "        train_r2_score = r2_score(y_train, y_train_pred)\n",
    "        train_rmse_score = np.sqrt(mean_squared_error(y_train, y_train_pred))\n",
    "        \n",
    "        # Predict on the test set\n",
    "        if test_size != 0:\n",
    "            dtest = xgb.DMatrix(X_test_scaled)\n",
    "            y_test_pred = bst.predict(dtest)\n",
    "            test_r2_score = r2_score(y_test, y_test_pred)\n",
    "            test_rmse_score = np.sqrt(mean_squared_error(y_test, y_test_pred))\n",
    "        \n",
    "        # Save the final scores for the given params\n",
    "        results['params'].append(temp_params)\n",
    "        results['cv_r2_score'].append(np.mean(temp_scores['r2']))\n",
    "        results['cv_rmse_score'].append(np.mean(temp_scores['rmse']))\n",
    "        results['train_r2_score'].append(train_r2_score)\n",
    "        results['train_rmse_score'].append(train_rmse_score)\n",
    "        results['model'].append(bst)\n",
    "        \n",
    "        if test_size != 0:\n",
    "            results['test_r2_score'].append(test_r2_score)\n",
    "            results['test_rmse_score'].append(test_rmse_score)\n",
    "        \n",
    "    return results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Errors Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [],
   "source": [
    "def error_analysis(X, y_true, y_pred):\n",
    "    \n",
    "    errors = y_pred - y_true\n",
    "    \n",
    "    sns.scatterplot(y_true, y_pred)\n",
    "    plt.title(\"y_pred as a function of y_true\", fontweight=\"bold\")\n",
    "    plt.xlabel(\"y_true\", fontweight=\"bold\")\n",
    "    plt.ylabel(\"y_pred\", fontweight=\"bold\")\n",
    "    plt.show()\n",
    "    \n",
    "    sns.distplot(errors, kde=False)\n",
    "    plt.title(\"Errors distribution\", fontweight=\"bold\")\n",
    "    plt.xlabel(\"Error value\", fontweight=\"bold\")\n",
    "    plt.ylabel(\"Total errors\", fontweight=\"bold\")\n",
    "    plt.show()\n",
    "    \n",
    "    sns.scatterplot(y_true, errors)\n",
    "    plt.title(\"Error value as a function of y_true\", fontweight=\"bold\")\n",
    "    plt.xlabel(\"y_true\", fontweight=\"bold\")\n",
    "    plt.ylabel(\"Error value\", fontweight=\"bold\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_prep = prepare_data(data)\n",
    "data_with_outliers_prep = prepare_data(data_with_outliers)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Site Energy Use - Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 299,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'max_depth': None,\n",
       " 'max_features': 'auto',\n",
       " 'min_samples_leaf': 1,\n",
       " 'min_samples_split': 2,\n",
       " 'n_estimators': 600,\n",
       " 'n_jobs': -1,\n",
       " 'random_state': 42}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'train_rmse': 526155.9997101225,\n",
       " 'train_r2': 0.9801344581186169,\n",
       " 'test_rmse': 1232320.5184747213,\n",
       " 'test_r2': 0.8801388862977408}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "param_grid = {'n_estimators': [600],\n",
    "              'max_features': ['auto'],\n",
    "              'n_jobs': [-1],\n",
    "              'random_state': [42],\n",
    "              'max_depth': [None],\n",
    "              'min_samples_leaf': [1],\n",
    "              'min_samples_split': [2],\n",
    "              }\n",
    "\n",
    "classifier1, y_test1, y_pred1, scores1, X_test1 = my_rf(data_prep.drop([target2, \"ENERGYSTARScore\"], axis=1), target1, param_grid, test_size=0.20)\n",
    "display(classifier1.best_params_)\n",
    "display(scores1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Site Energy Use - XGboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 306,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {'max_depth': [10, 20, 30, 50],\n",
    "          'eta': [0.1, 0.3, 0.5],\n",
    "          'min_child_weight': [1, 5, 10],\n",
    "          'subsample': [0.6, 0.8, 1.0],\n",
    "          'colsample_bytree': [0.6, 0.8, 1.0],\n",
    "          'objective': ['reg:squarederror'],\n",
    "          'nthread': [4]}\n",
    "\n",
    "classifier2 = my_xgb(data_prep.drop([target2, \"ENERGYSTARScore\"], axis=1), params, target1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 307,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>params</th>\n",
       "      <th>cv_r2_score</th>\n",
       "      <th>cv_rmse_score</th>\n",
       "      <th>train_r2_score</th>\n",
       "      <th>train_rmse_score</th>\n",
       "      <th>test_r2_score</th>\n",
       "      <th>test_rmse_score</th>\n",
       "      <th>model</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>301</th>\n",
       "      <td>{'max_depth': 50, 'eta': 0.5, 'min_child_weigh...</td>\n",
       "      <td>0.756758</td>\n",
       "      <td>1.837453e+06</td>\n",
       "      <td>0.997798</td>\n",
       "      <td>175184.242238</td>\n",
       "      <td>0.901592</td>\n",
       "      <td>1.116608e+06</td>\n",
       "      <td>&lt;xgboost.core.Booster object at 0x1354765f8&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>220</th>\n",
       "      <td>{'max_depth': 30, 'eta': 0.5, 'min_child_weigh...</td>\n",
       "      <td>0.761256</td>\n",
       "      <td>1.820608e+06</td>\n",
       "      <td>0.997734</td>\n",
       "      <td>177695.140451</td>\n",
       "      <td>0.900955</td>\n",
       "      <td>1.120212e+06</td>\n",
       "      <td>&lt;xgboost.core.Booster object at 0x12f8b2f60&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>142</th>\n",
       "      <td>{'max_depth': 20, 'eta': 0.5, 'min_child_weigh...</td>\n",
       "      <td>0.795182</td>\n",
       "      <td>1.686408e+06</td>\n",
       "      <td>0.998782</td>\n",
       "      <td>130261.711119</td>\n",
       "      <td>0.900523</td>\n",
       "      <td>1.122655e+06</td>\n",
       "      <td>&lt;xgboost.core.Booster object at 0x1282dd828&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>274</th>\n",
       "      <td>{'max_depth': 50, 'eta': 0.3, 'min_child_weigh...</td>\n",
       "      <td>0.783797</td>\n",
       "      <td>1.734048e+06</td>\n",
       "      <td>0.982691</td>\n",
       "      <td>491139.651906</td>\n",
       "      <td>0.900371</td>\n",
       "      <td>1.123512e+06</td>\n",
       "      <td>&lt;xgboost.core.Booster object at 0x12f8bda58&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>193</th>\n",
       "      <td>{'max_depth': 30, 'eta': 0.3, 'min_child_weigh...</td>\n",
       "      <td>0.782434</td>\n",
       "      <td>1.740074e+06</td>\n",
       "      <td>0.982333</td>\n",
       "      <td>496188.751357</td>\n",
       "      <td>0.900339</td>\n",
       "      <td>1.123691e+06</td>\n",
       "      <td>&lt;xgboost.core.Booster object at 0x12ab90ba8&gt;</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                params  cv_r2_score  \\\n",
       "301  {'max_depth': 50, 'eta': 0.5, 'min_child_weigh...     0.756758   \n",
       "220  {'max_depth': 30, 'eta': 0.5, 'min_child_weigh...     0.761256   \n",
       "142  {'max_depth': 20, 'eta': 0.5, 'min_child_weigh...     0.795182   \n",
       "274  {'max_depth': 50, 'eta': 0.3, 'min_child_weigh...     0.783797   \n",
       "193  {'max_depth': 30, 'eta': 0.3, 'min_child_weigh...     0.782434   \n",
       "\n",
       "     cv_rmse_score  train_r2_score  train_rmse_score  test_r2_score  \\\n",
       "301   1.837453e+06        0.997798     175184.242238       0.901592   \n",
       "220   1.820608e+06        0.997734     177695.140451       0.900955   \n",
       "142   1.686408e+06        0.998782     130261.711119       0.900523   \n",
       "274   1.734048e+06        0.982691     491139.651906       0.900371   \n",
       "193   1.740074e+06        0.982333     496188.751357       0.900339   \n",
       "\n",
       "     test_rmse_score                                         model  \n",
       "301     1.116608e+06  <xgboost.core.Booster object at 0x1354765f8>  \n",
       "220     1.120212e+06  <xgboost.core.Booster object at 0x12f8b2f60>  \n",
       "142     1.122655e+06  <xgboost.core.Booster object at 0x1282dd828>  \n",
       "274     1.123512e+06  <xgboost.core.Booster object at 0x12f8bda58>  \n",
       "193     1.123691e+06  <xgboost.core.Booster object at 0x12ab90ba8>  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(pd.DataFrame(classifier2).sort_values(by=\"test_rmse_score\").head(5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Site Energy Use - XGBoost with outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {'max_depth': [10, 20, 30, 50],\n",
    "          'eta': [0.1, 0.3, 0.5],\n",
    "          'min_child_weight': [1, 5, 10],\n",
    "          'subsample': [0.6, 0.8, 1.0],\n",
    "          'colsample_bytree': [0.6, 0.8, 1.0],\n",
    "          'objective': ['reg:squarederror'],\n",
    "          'nthread': [4]}\n",
    "\n",
    "classifier3 = my_xgb(data_with_outliers_prep.drop([target2, \"ENERGYSTARScore\"], axis=1), params, target1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(pd.DataFrame(classifier3).sort_values(by=\"test_rmse_score\").head(5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TotalGHGEmissions - Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {'n_estimators': [600],\n",
    "              'max_features': ['auto'],\n",
    "              'n_jobs': [-1],\n",
    "              'random_state': [42],\n",
    "              'max_depth': [None],\n",
    "              'min_samples_leaf': [1],\n",
    "              'min_samples_split': [2],\n",
    "              }\n",
    "\n",
    "classifier4, y_test4, y_pred4, scores4, X_test4 = my_rf(data_prep.drop([target1, \"ENERGYSTARScore\"], axis=1), target2, param_grid, test_size=0.20)\n",
    "display(classifier4.best_params_)\n",
    "display(scores4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TotalGHGEmissions - XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {'max_depth': [10, 20, 30, 50],\n",
    "          'eta': [0.1, 0.3, 0.5],\n",
    "          'min_child_weight': [1, 5, 10],\n",
    "          'subsample': [0.6, 0.8, 1.0],\n",
    "          'colsample_bytree': [0.6, 0.8, 1.0],\n",
    "          'objective': ['reg:squarederror'],\n",
    "          'nthread': [4]}\n",
    "\n",
    "classifier5 = my_xgb(data_prep.drop([target1, \"ENERGYSTARScore\"], axis=1), params, target2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(pd.DataFrame(classifier5).sort_values(by=\"test_rmse_score\").head(5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TotalGHGEmissions - XGBoost with ENERGYStarScore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {'max_depth': [10, 20, 30, 50],\n",
    "          'eta': [0.1, 0.3, 0.5],\n",
    "          'min_child_weight': [1, 5, 10],\n",
    "          'subsample': [0.6, 0.8, 1.0],\n",
    "          'colsample_bytree': [0.6, 0.8, 1.0],\n",
    "          'objective': ['reg:squarederror'],\n",
    "          'nthread': [4]}\n",
    "\n",
    "classifier2 = my_xgb(data_prep.drop([target1], axis=1), params, target2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(pd.DataFrame(classifier2).sort_values(by=\"test_rmse_score\").head(5))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
